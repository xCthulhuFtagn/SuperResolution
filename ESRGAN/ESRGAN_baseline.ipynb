{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовое решение кейса \"Улучшение качества видео - super resolution\" \n",
    "### Кейсодержатель: RUTUBE\n",
    "#### Описание решения: \n",
    "Задача Super Resolution (SR) - повышение разрешения изображений / видео с сохранением качества контента.\n",
    "\n",
    "Приведенное базовое решение основано на алгоритмическом повышении разрешения при помощи интерполяции и улучшении качества  изображения нейронной сетью.\n",
    "\n",
    "Однако данное решение не является единственным, существует большое количество разнообразных подходов, которые показывают лучшее качество на данной задаче. Про существующие методы решения задачи SR вы можете прочитать здесь: https://blog.paperspace.com/image-super-resolution/. \n",
    "\n",
    "Про baseline модель вы можете подробнее прочитать тут: https://arxiv.org/pdf/1501.00092.pdf.\n",
    "\n",
    "![Baseline модель](SRCNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем seed\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция инициализации весов модели\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели SRCNN происходит покадрово, поэтому выберем для обучения 5000 кадров случайным образом из 1000 видео (по 5 кадров из каждого видео)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим все необходимые папки, train_path - путь куда сохранятся кадры, video_path - путь к папке с исходными видео."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = 'path'\n",
    "# train_path = './train_frames'\n",
    "\n",
    "# lr_path = os.path.join(train_path, 'lr')\n",
    "# hr_path = os.path.join(train_path, 'hr')\n",
    "\n",
    "# if not os.path.exists(train_path):\n",
    "#     os.system(f'mkdir -p {train_path}')\n",
    "\n",
    "# if not os.path.exists(lr_path):\n",
    "#     os.system(f'mkdir -p {lr_path}')\n",
    "\n",
    "# if not os.path.exists(hr_path):\n",
    "#     os.system(f'mkdir -p {hr_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(video_path)\n",
    "# pairs = []\n",
    "# for f in files:\n",
    "#     if f.endswith('_144.mp4'):\n",
    "#         hr_name = f.split('_')[0] + '_480.mp4'\n",
    "#         pairs += [(f, hr_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_frames = 5000\n",
    "# size = int(n_frames // len(pairs))\n",
    "\n",
    "# save_idx = 0\n",
    "# for idx in tqdm(range(len(pairs))):\n",
    "#     pair = pairs[idx]\n",
    "\n",
    "#     lr = os.path.join(video_path, pair[0])\n",
    "#     hr = os.path.join(video_path, pair[1])\n",
    "\n",
    "#     lr_cap = cv2.VideoCapture(lr)\n",
    "#     hr_cap = cv2.VideoCapture(hr)\n",
    "\n",
    "#     lr_len = int(lr_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     hr_len = int(hr_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     assert lr_len == hr_len\n",
    "\n",
    "#     frames_idx = [i for i in range(lr_len)]\n",
    "#     if size:\n",
    "#         frames_idx = np.random.choice(frames_idx, size=size, replace=False)\n",
    "\n",
    "#     tmp_idx = 0\n",
    "#     while True:\n",
    "#         success_lr, frame_lr = lr_cap.read()\n",
    "#         success_hr, frame_hr = hr_cap.read()\n",
    "#         if not success_lr or not success_hr:\n",
    "#             break\n",
    "#         if tmp_idx in frames_idx:\n",
    "#             lr_save_path = os.path.join(lr_path, f'{save_idx}.jpg')\n",
    "#             hr_save_path = os.path.join(hr_path, f'{save_idx}.jpg')\n",
    "#             cv2.imwrite(lr_save_path, frame_lr)\n",
    "#             cv2.imwrite(hr_save_path, frame_hr)\n",
    "#             save_idx += 1\n",
    "#         tmp_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный класс формирует датасет для обучения / валидации и тестирования.\n",
    "\n",
    "Структура датасета: корневая папка -> папки train / val / test -> в каждой папке train / val / test лежит 2 папки lr и hr, внутри папок лежат изображения в низком и высоком разрешениях соответственно. Названия файлов в папке lr и hr должны совпадать, например lr/frame1.jpg и hr/frame1.jpg будет использоваться как одно изображение в разных разрешениях для обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SRDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аугментации ниже используются для получения torch.FloatTensor с нужными размерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SameTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ESRGAN_train import ESRGAN_Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект - trainer для запуска процесса обучения и инференса\n",
    "trainer = ESRGAN_Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacity of 7.92 GiB of which 70.62 MiB is free. Process 1967 has 84.80 MiB memory in use. Process 47939 has 3.82 GiB memory in use. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 20.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# запускаем процесс обучения\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DEV/course_work/SuperResolution/ESRGAN/ESRGAN_train.py:126\u001b[0m, in \u001b[0;36mESRGAN_Trainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m lr, hr \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    125\u001b[0m lr \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 126\u001b[0m hr \u001b[38;5;241m=\u001b[39m \u001b[43mhr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    129\u001b[0m valid \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_size)))\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 236.00 MiB. GPU 0 has a total capacity of 7.92 GiB of which 70.62 MiB is free. Process 1967 has 84.80 MiB memory in use. Process 47939 has 3.82 GiB memory in use. Including non-PyTorch memory, this process has 3.44 GiB memory in use. Of the allocated memory 3.32 GiB is allocated by PyTorch, and 20.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# запускаем процесс обучения\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем путь к видео низкого разрешения, которое лежит у нас на диске (lr_video) и путь к выходному видео, обработанному моделью в высоком разрешении (hr_video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_video = '/home/owner/Documents/DEV/Python/SuperResolution/rutube_hackaton_super_resolution_khabarovsk/train/1_144.mp4'\n",
    "hr_video = '/home/owner/Documents/DEV/Python/SuperResolution/rutube_hackaton_super_resolution_khabarovsk/train/1_480_newmp4'\n",
    "\n",
    "trainer.super_resolution(lr_video, hr_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
