{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовое решение кейса \"Улучшение качества видео - super resolution\" \n",
    "### Кейсодержатель: RUTUBE\n",
    "#### Описание решения: \n",
    "Задача Super Resolution (SR) - повышение разрешения изображений / видео с сохранением качества контента.\n",
    "\n",
    "Приведенное базовое решение основано на алгоритмическом повышении разрешения при помощи интерполяции и улучшении качества  изображения нейронной сетью.\n",
    "\n",
    "Однако данное решение не является единственным, существует большое количество разнообразных подходов, которые показывают лучшее качество на данной задаче. Про существующие методы решения задачи SR вы можете прочитать здесь: https://blog.paperspace.com/image-super-resolution/. \n",
    "\n",
    "Про baseline модель вы можете подробнее прочитать тут: https://arxiv.org/pdf/1501.00092.pdf.\n",
    "\n",
    "![Baseline модель](SRCNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# фиксируем seed\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция инициализации весов модели\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели SRCNN происходит покадрово, поэтому выберем для обучения 5000 кадров случайным образом из 1000 видео (по 5 кадров из каждого видео)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим все необходимые папки, train_path - путь куда сохранятся кадры, video_path - путь к папке с исходными видео."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = 'path'\n",
    "# train_path = './train_frames'\n",
    "\n",
    "# lr_path = os.path.join(train_path, 'lr')\n",
    "# hr_path = os.path.join(train_path, 'hr')\n",
    "\n",
    "# if not os.path.exists(train_path):\n",
    "#     os.system(f'mkdir -p {train_path}')\n",
    "\n",
    "# if not os.path.exists(lr_path):\n",
    "#     os.system(f'mkdir -p {lr_path}')\n",
    "\n",
    "# if not os.path.exists(hr_path):\n",
    "#     os.system(f'mkdir -p {hr_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = os.listdir(video_path)\n",
    "# pairs = []\n",
    "# for f in files:\n",
    "#     if f.endswith('_144.mp4'):\n",
    "#         hr_name = f.split('_')[0] + '_480.mp4'\n",
    "#         pairs += [(f, hr_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_frames = 5000\n",
    "# size = int(n_frames // len(pairs))\n",
    "\n",
    "# save_idx = 0\n",
    "# for idx in tqdm(range(len(pairs))):\n",
    "#     pair = pairs[idx]\n",
    "\n",
    "#     lr = os.path.join(video_path, pair[0])\n",
    "#     hr = os.path.join(video_path, pair[1])\n",
    "\n",
    "#     lr_cap = cv2.VideoCapture(lr)\n",
    "#     hr_cap = cv2.VideoCapture(hr)\n",
    "\n",
    "#     lr_len = int(lr_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     hr_len = int(hr_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "#     assert lr_len == hr_len\n",
    "\n",
    "#     frames_idx = [i for i in range(lr_len)]\n",
    "#     if size:\n",
    "#         frames_idx = np.random.choice(frames_idx, size=size, replace=False)\n",
    "\n",
    "#     tmp_idx = 0\n",
    "#     while True:\n",
    "#         success_lr, frame_lr = lr_cap.read()\n",
    "#         success_hr, frame_hr = hr_cap.read()\n",
    "#         if not success_lr or not success_hr:\n",
    "#             break\n",
    "#         if tmp_idx in frames_idx:\n",
    "#             lr_save_path = os.path.join(lr_path, f'{save_idx}.jpg')\n",
    "#             hr_save_path = os.path.join(hr_path, f'{save_idx}.jpg')\n",
    "#             cv2.imwrite(lr_save_path, frame_lr)\n",
    "#             cv2.imwrite(hr_save_path, frame_hr)\n",
    "#             save_idx += 1\n",
    "#         tmp_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный класс формирует датасет для обучения / валидации и тестирования.\n",
    "\n",
    "Структура датасета: корневая папка -> папки train / val / test -> в каждой папке train / val / test лежит 2 папки lr и hr, внутри папок лежат изображения в низком и высоком разрешениях соответственно. Названия файлов в папке lr и hr должны совпадать, например lr/frame1.jpg и hr/frame1.jpg будет использоваться как одно изображение в разных разрешениях для обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SRDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аугментации ниже используются для получения torch.FloatTensor с нужными размерами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SameTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ESRGAN_train import ESRGAN_Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем объект - trainer для запуска процесса обучения и инференса\n",
    "trainer = ESRGAN_Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запускаем процесс обучения\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Инференс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем путь к видео низкого разрешения, которое лежит у нас на диске (lr_video) и путь к выходному видео, обработанному моделью в высоком разрешении (hr_video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_video = '/home/owner/Documents/DEV/Python/SuperResolution/rutube_hackaton_super_resolution_khabarovsk/train/1_144.mp4'\n",
    "hr_video = '/home/owner/Documents/DEV/Python/SuperResolution/rutube_hackaton_super_resolution_khabarovsk/train/1_480_newmp4'\n",
    "\n",
    "trainer.super_resolution(lr_video, hr_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
